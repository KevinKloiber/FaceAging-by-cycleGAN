{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of run_train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1nI5UXxqpwi_PebaXtSKP1zvmsZ8YJQPX",
      "authorship_tag": "ABX9TyNz0gewKdFLNduKBdEGKCZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinKloiber/FaceAging-by-cycleGAN/blob/master/run_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WSexRERch5U",
        "outputId": "bedfd80d-dbc6-40e7-991e-cb7e316321bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%pip install dominate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/03/1ba70425be63f2aab42fbc98894fe5d90cdadd41f79bdc778b3e404cfd8f/dominate-2.5.2-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRoQZGtmzZKm",
        "outputId": "f1eb473b-ec66-4969-8b0e-ecee46c7bb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! npm i -g npm\n",
        "get_ipython().system_raw('python3 -m pip install visdom')\n",
        "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')\n",
        "get_ipython().system_raw('lt --port 8097 >> url.txt 2>&1 &')\n",
        "import time\n",
        "time.sleep(5)\n",
        "! cat url.txt\n",
        "import visdom\n",
        "time.sleep(5)\n",
        "vis = visdom.Visdom(port='8097')\n",
        "print(vis)\n",
        "time.sleep(3)\n",
        "vis.text('testing')\n",
        "! cat visdomlog.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/npm -> /tools/node/lib/node_modules/npm/bin/npm-cli.js\n",
            "/tools/node/bin/npx -> /tools/node/lib/node_modules/npm/bin/npx-cli.js\n",
            "\u001b[K\u001b[?25h+ npm@6.14.8\n",
            "added 324 packages from 161 contributors, removed 423 packages and updated 61 packages in 13.972s\n",
            "/bin/bash: lt: command not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up a new session...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<visdom.Visdom object at 0x7ff726a229b0>\n",
            "INFO:root:Application Started\n",
            "INFO:tornado.access:200 POST /env/main (127.0.0.1) 2.77ms\n",
            "INFO:tornado.access:101 GET /vis_socket (127.0.0.1) 0.56ms\n",
            "INFO:root:Opened visdom socket from ip: 127.0.0.1\n",
            "INFO:tornado.access:200 POST /events (127.0.0.1) 0.78ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a5ABH2PDYZZ",
        "outputId": "43980205-8834-4011-e74c-04d8e187dd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%run \"/content/drive/My Drive/FaceAging-by-cycleGAN/train.py\" --dataroot \"/content/drive/My Drive/FaceAging-by-cycleGAN/dataset/young2old\" --checkpoints_dir \"/content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints\" --name bmi_cyclegan --model cycle_gan --continue_train --epoch_count '176'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "         D_A_freeze_layer: 0                             \n",
            "         D_B_freeze_layer: 0                             \n",
            "         G_A_freeze_layer: 0                             \n",
            "         G_B_freeze_layer: 0                             \n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints\t[default: ./checkpoints]\n",
            "           continue_train: True                          \t[default: False]\n",
            "                 dataroot: /content/drive/My Drive/FaceAging-by-cycleGAN/dataset/young2old\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 176                           \t[default: 1]\n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                 loadSize: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "               n_layers_D: 3                             \n",
            "                     name: bmi_cyclegan                  \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "   pretrained_model_epoch: 1                             \n",
            "    pretrained_model_name:                               \n",
            " pretrained_model_subname:                               \n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "     use_pretrained_model: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "#training images = 628\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "loading the model from /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints/bmi_cyclegan/latest_net_G_A.pth\n",
            "loading the model from /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints/bmi_cyclegan/latest_net_G_B.pth\n",
            "loading the model from /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints/bmi_cyclegan/latest_net_D_A.pth\n",
            "loading the model from /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints/bmi_cyclegan/latest_net_D_B.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up a new session...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_A] Total number of trainable parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of trainable parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_A] Total number of trainable parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of trainable parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory /content/drive/My Drive/FaceAging-by-cycleGAN/checkpoints/bmi_cyclegan/web...\n",
            "(epoch: 176, iters: 100, time: 1.377, data: 1.999) D_A: 0.136 G_A: 0.353 cycle_A: 0.470 idt_A: 0.181 D_B: 0.072 G_B: 0.648 cycle_B: 0.363 idt_B: 0.163 \n",
            "(epoch: 176, iters: 200, time: 1.383, data: 0.003) D_A: 0.185 G_A: 0.306 cycle_A: 0.475 idt_A: 0.301 D_B: 0.245 G_B: 0.281 cycle_B: 0.459 idt_B: 0.206 \n",
            "(epoch: 176, iters: 300, time: 1.385, data: 0.000) D_A: 0.172 G_A: 0.421 cycle_A: 0.524 idt_A: 0.301 D_B: 0.153 G_B: 0.309 cycle_B: 0.402 idt_B: 0.214 \n",
            "(epoch: 176, iters: 400, time: 15.952, data: 0.002) D_A: 0.140 G_A: 0.362 cycle_A: 0.463 idt_A: 0.221 D_B: 0.261 G_B: 0.483 cycle_B: 0.418 idt_B: 0.202 \n",
            "(epoch: 176, iters: 500, time: 1.390, data: 0.002) D_A: 0.157 G_A: 0.339 cycle_A: 0.623 idt_A: 0.227 D_B: 0.214 G_B: 0.458 cycle_B: 0.454 idt_B: 0.307 \n",
            "(epoch: 176, iters: 600, time: 1.385, data: 0.002) D_A: 0.272 G_A: 0.391 cycle_A: 0.323 idt_A: 0.198 D_B: 0.132 G_B: 0.305 cycle_B: 0.342 idt_B: 0.195 \n",
            "End of epoch 176 / 200 \t Time Taken: 839 sec\n",
            "learning rate = 0.0000475\n",
            "(epoch: 177, iters: 72, time: 1.386, data: 0.002) D_A: 0.194 G_A: 0.206 cycle_A: 0.457 idt_A: 0.243 D_B: 0.089 G_B: 0.535 cycle_B: 0.331 idt_B: 0.194 \n",
            "(epoch: 177, iters: 172, time: 3.576, data: 0.002) D_A: 0.193 G_A: 0.197 cycle_A: 0.501 idt_A: 0.174 D_B: 0.229 G_B: 0.577 cycle_B: 0.463 idt_B: 0.252 \n",
            "(epoch: 177, iters: 272, time: 1.382, data: 0.002) D_A: 0.181 G_A: 0.288 cycle_A: 0.504 idt_A: 0.299 D_B: 0.111 G_B: 0.429 cycle_B: 0.584 idt_B: 0.204 \n",
            "(epoch: 177, iters: 372, time: 1.384, data: 0.002) D_A: 0.128 G_A: 0.488 cycle_A: 0.464 idt_A: 0.306 D_B: 0.164 G_B: 0.511 cycle_B: 0.428 idt_B: 0.219 \n",
            "(epoch: 177, iters: 472, time: 1.376, data: 0.002) D_A: 0.151 G_A: 0.503 cycle_A: 0.535 idt_A: 0.277 D_B: 0.188 G_B: 0.200 cycle_B: 0.466 idt_B: 0.162 \n",
            "(epoch: 177, iters: 572, time: 3.457, data: 0.003) D_A: 0.137 G_A: 0.555 cycle_A: 0.465 idt_A: 0.283 D_B: 0.325 G_B: 0.395 cycle_B: 0.349 idt_B: 0.232 \n",
            "End of epoch 177 / 200 \t Time Taken: 823 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 178, iters: 44, time: 1.385, data: 0.002) D_A: 0.106 G_A: 0.492 cycle_A: 0.698 idt_A: 0.288 D_B: 0.156 G_B: 0.304 cycle_B: 0.600 idt_B: 0.338 \n",
            "(epoch: 178, iters: 144, time: 1.389, data: 0.002) D_A: 0.150 G_A: 0.497 cycle_A: 0.547 idt_A: 0.260 D_B: 0.103 G_B: 0.491 cycle_B: 0.426 idt_B: 0.232 \n",
            "(epoch: 178, iters: 244, time: 1.385, data: 0.002) D_A: 0.355 G_A: 0.192 cycle_A: 0.389 idt_A: 0.208 D_B: 0.356 G_B: 0.219 cycle_B: 0.465 idt_B: 0.247 \n",
            "(epoch: 178, iters: 344, time: 3.450, data: 0.002) D_A: 0.217 G_A: 0.260 cycle_A: 0.396 idt_A: 0.196 D_B: 0.350 G_B: 0.552 cycle_B: 0.464 idt_B: 0.310 \n",
            "(epoch: 178, iters: 444, time: 1.388, data: 0.002) D_A: 0.065 G_A: 0.622 cycle_A: 0.633 idt_A: 0.178 D_B: 0.155 G_B: 0.484 cycle_B: 0.708 idt_B: 0.244 \n",
            "(epoch: 178, iters: 544, time: 1.380, data: 0.002) D_A: 0.104 G_A: 0.447 cycle_A: 0.502 idt_A: 0.316 D_B: 0.211 G_B: 0.641 cycle_B: 0.615 idt_B: 0.236 \n",
            "End of epoch 178 / 200 \t Time Taken: 821 sec\n",
            "learning rate = 0.0000436\n",
            "(epoch: 179, iters: 16, time: 1.385, data: 0.002) D_A: 0.197 G_A: 0.765 cycle_A: 0.664 idt_A: 0.274 D_B: 0.155 G_B: 0.366 cycle_B: 0.415 idt_B: 0.215 \n",
            "(epoch: 179, iters: 116, time: 3.570, data: 0.002) D_A: 0.103 G_A: 0.534 cycle_A: 0.536 idt_A: 0.172 D_B: 0.213 G_B: 0.622 cycle_B: 0.352 idt_B: 0.297 \n",
            "(epoch: 179, iters: 216, time: 1.389, data: 0.002) D_A: 0.151 G_A: 0.518 cycle_A: 0.797 idt_A: 0.238 D_B: 0.123 G_B: 0.445 cycle_B: 0.433 idt_B: 0.251 \n",
            "(epoch: 179, iters: 316, time: 1.385, data: 0.002) D_A: 0.075 G_A: 0.552 cycle_A: 0.609 idt_A: 0.150 D_B: 0.261 G_B: 0.387 cycle_B: 0.444 idt_B: 0.233 \n",
            "(epoch: 179, iters: 416, time: 1.389, data: 0.002) D_A: 0.097 G_A: 0.477 cycle_A: 0.616 idt_A: 0.201 D_B: 0.228 G_B: 0.378 cycle_B: 0.402 idt_B: 0.270 \n",
            "(epoch: 179, iters: 516, time: 3.441, data: 0.002) D_A: 0.087 G_A: 0.193 cycle_A: 0.395 idt_A: 0.273 D_B: 0.192 G_B: 0.547 cycle_B: 0.495 idt_B: 0.186 \n",
            "(epoch: 179, iters: 616, time: 1.391, data: 0.002) D_A: 0.132 G_A: 0.518 cycle_A: 0.387 idt_A: 0.273 D_B: 0.118 G_B: 0.484 cycle_B: 0.491 idt_B: 0.167 \n",
            "End of epoch 179 / 200 \t Time Taken: 824 sec\n",
            "learning rate = 0.0000416\n",
            "(epoch: 180, iters: 88, time: 1.397, data: 0.003) D_A: 0.094 G_A: 0.611 cycle_A: 0.845 idt_A: 0.182 D_B: 0.057 G_B: 0.566 cycle_B: 0.356 idt_B: 0.288 \n",
            "(epoch: 180, iters: 188, time: 1.388, data: 0.002) D_A: 0.077 G_A: 0.523 cycle_A: 0.487 idt_A: 0.205 D_B: 0.193 G_B: 0.425 cycle_B: 0.458 idt_B: 0.242 \n",
            "(epoch: 180, iters: 288, time: 3.581, data: 0.002) D_A: 0.182 G_A: 0.315 cycle_A: 0.387 idt_A: 0.241 D_B: 0.259 G_B: 0.265 cycle_B: 0.340 idt_B: 0.249 \n",
            "(epoch: 180, iters: 388, time: 1.383, data: 0.002) D_A: 0.240 G_A: 0.580 cycle_A: 0.446 idt_A: 0.289 D_B: 0.183 G_B: 0.439 cycle_B: 0.528 idt_B: 0.276 \n",
            "(epoch: 180, iters: 488, time: 1.393, data: 0.002) D_A: 0.186 G_A: 0.604 cycle_A: 0.655 idt_A: 0.309 D_B: 0.106 G_B: 0.608 cycle_B: 0.557 idt_B: 0.246 \n",
            "(epoch: 180, iters: 588, time: 1.387, data: 0.002) D_A: 0.178 G_A: 0.618 cycle_A: 0.494 idt_A: 0.233 D_B: 0.186 G_B: 0.297 cycle_B: 0.422 idt_B: 0.224 \n",
            "saving the model at the end of epoch 180, iters 3140\n",
            "End of epoch 180 / 200 \t Time Taken: 824 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 181, iters: 60, time: 3.450, data: 0.002) D_A: 0.278 G_A: 0.146 cycle_A: 0.457 idt_A: 0.161 D_B: 0.227 G_B: 0.567 cycle_B: 0.403 idt_B: 0.253 \n",
            "(epoch: 181, iters: 160, time: 1.395, data: 0.002) D_A: 0.136 G_A: 0.667 cycle_A: 0.518 idt_A: 0.200 D_B: 0.246 G_B: 0.379 cycle_B: 0.330 idt_B: 0.238 \n",
            "(epoch: 181, iters: 260, time: 1.386, data: 0.002) D_A: 0.282 G_A: 0.326 cycle_A: 0.363 idt_A: 0.284 D_B: 0.137 G_B: 0.751 cycle_B: 0.398 idt_B: 0.222 \n",
            "(epoch: 181, iters: 360, time: 1.378, data: 0.002) D_A: 0.210 G_A: 0.229 cycle_A: 0.426 idt_A: 0.244 D_B: 0.287 G_B: 0.506 cycle_B: 0.511 idt_B: 0.221 \n",
            "(epoch: 181, iters: 460, time: 3.554, data: 0.002) D_A: 0.129 G_A: 0.441 cycle_A: 0.576 idt_A: 0.168 D_B: 0.181 G_B: 0.502 cycle_B: 0.418 idt_B: 0.279 \n",
            "(epoch: 181, iters: 560, time: 1.371, data: 0.002) D_A: 0.188 G_A: 0.441 cycle_A: 0.574 idt_A: 0.241 D_B: 0.161 G_B: 0.511 cycle_B: 0.459 idt_B: 0.230 \n",
            "End of epoch 181 / 200 \t Time Taken: 822 sec\n",
            "learning rate = 0.0000376\n",
            "(epoch: 182, iters: 32, time: 1.348, data: 0.002) D_A: 0.213 G_A: 0.639 cycle_A: 0.531 idt_A: 0.204 D_B: 0.217 G_B: 0.209 cycle_B: 0.385 idt_B: 0.217 \n",
            "(epoch: 182, iters: 132, time: 1.354, data: 0.002) D_A: 0.127 G_A: 0.530 cycle_A: 0.452 idt_A: 0.202 D_B: 0.097 G_B: 0.523 cycle_B: 0.438 idt_B: 0.195 \n",
            "(epoch: 182, iters: 232, time: 3.466, data: 0.002) D_A: 0.168 G_A: 0.726 cycle_A: 0.462 idt_A: 0.407 D_B: 0.104 G_B: 0.414 cycle_B: 0.446 idt_B: 0.157 \n",
            "(epoch: 182, iters: 332, time: 1.362, data: 0.002) D_A: 0.226 G_A: 0.229 cycle_A: 0.451 idt_A: 0.253 D_B: 0.256 G_B: 0.643 cycle_B: 0.473 idt_B: 0.264 \n",
            "(epoch: 182, iters: 432, time: 1.364, data: 0.002) D_A: 0.092 G_A: 0.741 cycle_A: 0.900 idt_A: 0.182 D_B: 0.120 G_B: 0.648 cycle_B: 0.433 idt_B: 0.359 \n",
            "(epoch: 182, iters: 532, time: 1.329, data: 0.002) D_A: 0.251 G_A: 0.470 cycle_A: 0.538 idt_A: 0.188 D_B: 0.123 G_B: 0.879 cycle_B: 0.738 idt_B: 0.205 \n",
            "End of epoch 182 / 200 \t Time Taken: 802 sec\n",
            "learning rate = 0.0000356\n",
            "(epoch: 183, iters: 4, time: 3.512, data: 0.002) D_A: 0.091 G_A: 0.802 cycle_A: 0.760 idt_A: 0.143 D_B: 0.098 G_B: 0.266 cycle_B: 0.373 idt_B: 0.334 \n",
            "(epoch: 183, iters: 104, time: 1.354, data: 0.002) D_A: 0.200 G_A: 0.331 cycle_A: 0.507 idt_A: 0.202 D_B: 0.158 G_B: 0.558 cycle_B: 0.362 idt_B: 0.286 \n",
            "(epoch: 183, iters: 204, time: 1.350, data: 0.002) D_A: 0.094 G_A: 0.404 cycle_A: 0.564 idt_A: 0.219 D_B: 0.276 G_B: 0.570 cycle_B: 0.340 idt_B: 0.314 \n",
            "(epoch: 183, iters: 304, time: 1.370, data: 0.002) D_A: 0.076 G_A: 0.317 cycle_A: 0.410 idt_A: 0.214 D_B: 0.284 G_B: 0.410 cycle_B: 0.435 idt_B: 0.246 \n",
            "(epoch: 183, iters: 404, time: 3.464, data: 0.002) D_A: 0.149 G_A: 0.341 cycle_A: 0.718 idt_A: 0.241 D_B: 0.090 G_B: 0.672 cycle_B: 0.533 idt_B: 0.331 \n",
            "(epoch: 183, iters: 504, time: 1.362, data: 0.002) D_A: 0.167 G_A: 0.468 cycle_A: 0.528 idt_A: 0.215 D_B: 0.084 G_B: 0.479 cycle_B: 0.432 idt_B: 0.293 \n",
            "(epoch: 183, iters: 604, time: 1.352, data: 0.002) D_A: 0.136 G_A: 0.381 cycle_A: 0.557 idt_A: 0.328 D_B: 0.221 G_B: 0.251 cycle_B: 0.433 idt_B: 0.257 \n",
            "saving the latest model (epoch 183, total_steps 5000)\n",
            "End of epoch 183 / 200 \t Time Taken: 807 sec\n",
            "learning rate = 0.0000337\n",
            "(epoch: 184, iters: 76, time: 1.399, data: 0.002) D_A: 0.110 G_A: 0.189 cycle_A: 0.788 idt_A: 0.157 D_B: 0.126 G_B: 0.523 cycle_B: 0.375 idt_B: 0.302 \n",
            "(epoch: 184, iters: 176, time: 3.526, data: 0.002) D_A: 0.141 G_A: 0.520 cycle_A: 0.435 idt_A: 0.186 D_B: 0.146 G_B: 0.578 cycle_B: 0.318 idt_B: 0.190 \n",
            "(epoch: 184, iters: 276, time: 1.367, data: 0.002) D_A: 0.159 G_A: 0.930 cycle_A: 0.667 idt_A: 0.260 D_B: 0.085 G_B: 0.462 cycle_B: 0.463 idt_B: 0.261 \n",
            "(epoch: 184, iters: 376, time: 1.387, data: 0.003) D_A: 0.173 G_A: 0.660 cycle_A: 0.431 idt_A: 0.305 D_B: 0.186 G_B: 0.489 cycle_B: 0.421 idt_B: 0.176 \n",
            "(epoch: 184, iters: 476, time: 1.354, data: 0.002) D_A: 0.105 G_A: 1.101 cycle_A: 0.423 idt_A: 0.236 D_B: 0.032 G_B: 0.504 cycle_B: 0.368 idt_B: 0.185 \n",
            "(epoch: 184, iters: 576, time: 3.676, data: 0.002) D_A: 0.140 G_A: 0.534 cycle_A: 0.417 idt_A: 0.301 D_B: 0.149 G_B: 0.599 cycle_B: 0.665 idt_B: 0.183 \n",
            "End of epoch 184 / 200 \t Time Taken: 808 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 185, iters: 48, time: 1.384, data: 0.002) D_A: 0.106 G_A: 0.325 cycle_A: 0.394 idt_A: 0.233 D_B: 0.129 G_B: 0.455 cycle_B: 0.427 idt_B: 0.149 \n",
            "(epoch: 185, iters: 148, time: 1.343, data: 0.002) D_A: 0.138 G_A: 0.704 cycle_A: 0.536 idt_A: 0.197 D_B: 0.190 G_B: 0.168 cycle_B: 0.395 idt_B: 0.208 \n",
            "(epoch: 185, iters: 248, time: 1.346, data: 0.002) D_A: 0.163 G_A: 0.456 cycle_A: 0.601 idt_A: 0.170 D_B: 0.034 G_B: 0.873 cycle_B: 0.493 idt_B: 0.203 \n",
            "(epoch: 185, iters: 348, time: 3.542, data: 0.002) D_A: 0.154 G_A: 0.375 cycle_A: 0.441 idt_A: 0.278 D_B: 0.138 G_B: 0.394 cycle_B: 0.546 idt_B: 0.217 \n",
            "(epoch: 185, iters: 448, time: 1.357, data: 0.002) D_A: 0.249 G_A: 0.260 cycle_A: 0.579 idt_A: 0.225 D_B: 0.258 G_B: 0.528 cycle_B: 0.479 idt_B: 0.276 \n",
            "(epoch: 185, iters: 548, time: 1.371, data: 0.002) D_A: 0.242 G_A: 0.295 cycle_A: 0.554 idt_A: 0.214 D_B: 0.305 G_B: 0.441 cycle_B: 0.365 idt_B: 0.269 \n",
            "saving the model at the end of epoch 185, iters 6280\n",
            "End of epoch 185 / 200 \t Time Taken: 806 sec\n",
            "learning rate = 0.0000297\n",
            "(epoch: 186, iters: 20, time: 1.359, data: 0.002) D_A: 0.067 G_A: 0.496 cycle_A: 0.486 idt_A: 0.173 D_B: 0.115 G_B: 0.491 cycle_B: 0.460 idt_B: 0.265 \n",
            "(epoch: 186, iters: 120, time: 3.708, data: 0.002) D_A: 0.249 G_A: 0.448 cycle_A: 0.421 idt_A: 0.141 D_B: 0.097 G_B: 0.409 cycle_B: 0.346 idt_B: 0.345 \n",
            "(epoch: 186, iters: 220, time: 1.361, data: 0.002) D_A: 0.162 G_A: 0.608 cycle_A: 0.556 idt_A: 0.236 D_B: 0.119 G_B: 0.514 cycle_B: 0.402 idt_B: 0.256 \n",
            "(epoch: 186, iters: 320, time: 1.353, data: 0.002) D_A: 0.265 G_A: 0.249 cycle_A: 0.499 idt_A: 0.282 D_B: 0.218 G_B: 0.577 cycle_B: 0.377 idt_B: 0.208 \n",
            "(epoch: 186, iters: 420, time: 1.352, data: 0.002) D_A: 0.121 G_A: 0.412 cycle_A: 0.585 idt_A: 0.154 D_B: 0.327 G_B: 0.556 cycle_B: 0.492 idt_B: 0.404 \n",
            "(epoch: 186, iters: 520, time: 3.609, data: 0.002) D_A: 0.099 G_A: 0.601 cycle_A: 0.322 idt_A: 0.306 D_B: 0.098 G_B: 0.465 cycle_B: 0.670 idt_B: 0.243 \n",
            "(epoch: 186, iters: 620, time: 1.363, data: 0.002) D_A: 0.134 G_A: 0.423 cycle_A: 0.711 idt_A: 0.242 D_B: 0.142 G_B: 0.558 cycle_B: 0.405 idt_B: 0.257 \n",
            "End of epoch 186 / 200 \t Time Taken: 810 sec\n",
            "learning rate = 0.0000277\n",
            "(epoch: 187, iters: 92, time: 1.368, data: 0.002) D_A: 0.154 G_A: 0.409 cycle_A: 0.595 idt_A: 0.180 D_B: 0.143 G_B: 0.476 cycle_B: 0.454 idt_B: 0.209 \n",
            "(epoch: 187, iters: 192, time: 1.360, data: 0.002) D_A: 0.091 G_A: 0.557 cycle_A: 0.365 idt_A: 0.198 D_B: 0.177 G_B: 0.381 cycle_B: 0.439 idt_B: 0.232 \n",
            "(epoch: 187, iters: 292, time: 3.606, data: 0.002) D_A: 0.235 G_A: 0.504 cycle_A: 0.730 idt_A: 0.191 D_B: 0.172 G_B: 0.329 cycle_B: 0.417 idt_B: 0.333 \n",
            "(epoch: 187, iters: 392, time: 1.351, data: 0.002) D_A: 0.201 G_A: 0.587 cycle_A: 0.591 idt_A: 0.218 D_B: 0.137 G_B: 0.332 cycle_B: 0.365 idt_B: 0.233 \n",
            "(epoch: 187, iters: 492, time: 1.353, data: 0.002) D_A: 0.128 G_A: 0.617 cycle_A: 0.576 idt_A: 0.237 D_B: 0.121 G_B: 0.482 cycle_B: 0.421 idt_B: 0.281 \n",
            "(epoch: 187, iters: 592, time: 1.374, data: 0.002) D_A: 0.235 G_A: 0.256 cycle_A: 0.548 idt_A: 0.257 D_B: 0.264 G_B: 0.581 cycle_B: 0.573 idt_B: 0.391 \n",
            "End of epoch 187 / 200 \t Time Taken: 806 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 188, iters: 64, time: 3.678, data: 0.002) D_A: 0.224 G_A: 0.575 cycle_A: 0.618 idt_A: 0.236 D_B: 0.105 G_B: 0.506 cycle_B: 0.405 idt_B: 0.334 \n",
            "(epoch: 188, iters: 164, time: 1.368, data: 0.002) D_A: 0.124 G_A: 0.503 cycle_A: 0.488 idt_A: 0.183 D_B: 0.079 G_B: 0.491 cycle_B: 0.359 idt_B: 0.205 \n",
            "(epoch: 188, iters: 264, time: 1.354, data: 0.002) D_A: 0.153 G_A: 0.359 cycle_A: 0.437 idt_A: 0.300 D_B: 0.284 G_B: 0.287 cycle_B: 0.400 idt_B: 0.230 \n",
            "(epoch: 188, iters: 364, time: 1.377, data: 0.002) D_A: 0.080 G_A: 0.504 cycle_A: 0.592 idt_A: 0.137 D_B: 0.089 G_B: 0.384 cycle_B: 0.440 idt_B: 0.243 \n",
            "(epoch: 188, iters: 464, time: 3.691, data: 0.005) D_A: 0.073 G_A: 0.749 cycle_A: 0.495 idt_A: 0.163 D_B: 0.143 G_B: 0.390 cycle_B: 0.380 idt_B: 0.218 \n",
            "(epoch: 188, iters: 564, time: 1.369, data: 0.002) D_A: 0.074 G_A: 0.615 cycle_A: 0.625 idt_A: 0.209 D_B: 0.147 G_B: 0.532 cycle_B: 0.658 idt_B: 0.270 \n",
            "End of epoch 188 / 200 \t Time Taken: 811 sec\n",
            "learning rate = 0.0000238\n",
            "(epoch: 189, iters: 36, time: 1.376, data: 0.002) D_A: 0.177 G_A: 0.700 cycle_A: 0.646 idt_A: 0.248 D_B: 0.158 G_B: 0.437 cycle_B: 0.387 idt_B: 0.265 \n",
            "(epoch: 189, iters: 136, time: 1.374, data: 0.002) D_A: 0.099 G_A: 0.308 cycle_A: 0.393 idt_A: 0.253 D_B: 0.307 G_B: 0.295 cycle_B: 0.558 idt_B: 0.171 \n",
            "(epoch: 189, iters: 236, time: 3.747, data: 0.002) D_A: 0.211 G_A: 0.355 cycle_A: 0.346 idt_A: 0.244 D_B: 0.176 G_B: 0.418 cycle_B: 0.489 idt_B: 0.146 \n",
            "(epoch: 189, iters: 336, time: 1.368, data: 0.002) D_A: 0.070 G_A: 0.448 cycle_A: 0.614 idt_A: 0.279 D_B: 0.154 G_B: 0.437 cycle_B: 0.495 idt_B: 0.265 \n",
            "(epoch: 189, iters: 436, time: 1.372, data: 0.002) D_A: 0.212 G_A: 0.949 cycle_A: 0.692 idt_A: 0.236 D_B: 0.094 G_B: 0.327 cycle_B: 0.464 idt_B: 0.216 \n",
            "(epoch: 189, iters: 536, time: 1.368, data: 0.002) D_A: 0.100 G_A: 0.564 cycle_A: 0.705 idt_A: 0.225 D_B: 0.150 G_B: 0.326 cycle_B: 0.395 idt_B: 0.305 \n",
            "End of epoch 189 / 200 \t Time Taken: 813 sec\n",
            "learning rate = 0.0000218\n",
            "(epoch: 190, iters: 8, time: 3.744, data: 0.002) D_A: 0.140 G_A: 0.349 cycle_A: 0.630 idt_A: 0.226 D_B: 0.214 G_B: 0.351 cycle_B: 0.695 idt_B: 0.381 \n",
            "(epoch: 190, iters: 108, time: 1.368, data: 0.002) D_A: 0.155 G_A: 0.707 cycle_A: 0.449 idt_A: 0.216 D_B: 0.215 G_B: 0.192 cycle_B: 0.417 idt_B: 0.281 \n",
            "(epoch: 190, iters: 208, time: 1.369, data: 0.002) D_A: 0.179 G_A: 0.436 cycle_A: 0.595 idt_A: 0.247 D_B: 0.238 G_B: 0.403 cycle_B: 0.359 idt_B: 0.281 \n",
            "(epoch: 190, iters: 308, time: 1.376, data: 0.002) D_A: 0.077 G_A: 0.247 cycle_A: 0.350 idt_A: 0.157 D_B: 0.248 G_B: 0.722 cycle_B: 0.504 idt_B: 0.281 \n",
            "(epoch: 190, iters: 408, time: 3.579, data: 0.002) D_A: 0.248 G_A: 0.456 cycle_A: 0.459 idt_A: 0.174 D_B: 0.226 G_B: 0.495 cycle_B: 0.359 idt_B: 0.368 \n",
            "(epoch: 190, iters: 508, time: 1.378, data: 0.002) D_A: 0.072 G_A: 0.521 cycle_A: 0.458 idt_A: 0.195 D_B: 0.238 G_B: 0.799 cycle_B: 0.734 idt_B: 0.196 \n",
            "(epoch: 190, iters: 608, time: 1.375, data: 0.002) D_A: 0.212 G_A: 0.603 cycle_A: 0.551 idt_A: 0.283 D_B: 0.134 G_B: 0.220 cycle_B: 0.365 idt_B: 0.227 \n",
            "saving the model at the end of epoch 190, iters 9420\n",
            "End of epoch 190 / 200 \t Time Taken: 816 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 191, iters: 80, time: 1.373, data: 0.002) D_A: 0.077 G_A: 0.403 cycle_A: 0.369 idt_A: 0.259 D_B: 0.096 G_B: 0.797 cycle_B: 0.275 idt_B: 0.171 \n",
            "(epoch: 191, iters: 180, time: 3.746, data: 0.002) D_A: 0.199 G_A: 0.290 cycle_A: 0.495 idt_A: 0.164 D_B: 0.119 G_B: 0.516 cycle_B: 0.409 idt_B: 0.203 \n",
            "(epoch: 191, iters: 280, time: 1.370, data: 0.002) D_A: 0.239 G_A: 0.357 cycle_A: 0.461 idt_A: 0.235 D_B: 0.187 G_B: 0.418 cycle_B: 0.432 idt_B: 0.260 \n",
            "(epoch: 191, iters: 380, time: 1.366, data: 0.002) D_A: 0.139 G_A: 0.397 cycle_A: 0.389 idt_A: 0.155 D_B: 0.216 G_B: 0.901 cycle_B: 0.381 idt_B: 0.233 \n",
            "(epoch: 191, iters: 480, time: 1.372, data: 0.002) D_A: 0.141 G_A: 0.316 cycle_A: 0.396 idt_A: 0.266 D_B: 0.198 G_B: 0.500 cycle_B: 0.455 idt_B: 0.177 \n",
            "(epoch: 191, iters: 580, time: 3.554, data: 0.002) D_A: 0.118 G_A: 0.654 cycle_A: 0.599 idt_A: 0.122 D_B: 0.099 G_B: 0.387 cycle_B: 0.305 idt_B: 0.220 \n",
            "saving the latest model (epoch 191, total_steps 10000)\n",
            "End of epoch 191 / 200 \t Time Taken: 816 sec\n",
            "learning rate = 0.0000178\n",
            "(epoch: 192, iters: 52, time: 1.381, data: 0.002) D_A: 0.167 G_A: 0.331 cycle_A: 0.580 idt_A: 0.196 D_B: 0.277 G_B: 0.392 cycle_B: 0.442 idt_B: 0.293 \n",
            "(epoch: 192, iters: 152, time: 1.371, data: 0.002) D_A: 0.143 G_A: 0.536 cycle_A: 0.535 idt_A: 0.259 D_B: 0.132 G_B: 0.429 cycle_B: 0.418 idt_B: 0.224 \n",
            "(epoch: 192, iters: 252, time: 1.378, data: 0.002) D_A: 0.112 G_A: 0.498 cycle_A: 0.466 idt_A: 0.124 D_B: 0.289 G_B: 0.232 cycle_B: 0.359 idt_B: 0.267 \n",
            "(epoch: 192, iters: 352, time: 3.718, data: 0.002) D_A: 0.232 G_A: 0.366 cycle_A: 0.375 idt_A: 0.202 D_B: 0.132 G_B: 0.494 cycle_B: 0.389 idt_B: 0.227 \n",
            "(epoch: 192, iters: 452, time: 1.366, data: 0.002) D_A: 0.232 G_A: 0.536 cycle_A: 0.584 idt_A: 0.287 D_B: 0.137 G_B: 0.532 cycle_B: 0.465 idt_B: 0.236 \n",
            "(epoch: 192, iters: 552, time: 1.373, data: 0.002) D_A: 0.111 G_A: 0.520 cycle_A: 0.422 idt_A: 0.295 D_B: 0.111 G_B: 0.360 cycle_B: 0.398 idt_B: 0.203 \n",
            "End of epoch 192 / 200 \t Time Taken: 814 sec\n",
            "learning rate = 0.0000158\n",
            "(epoch: 193, iters: 24, time: 1.394, data: 0.005) D_A: 0.209 G_A: 0.269 cycle_A: 0.459 idt_A: 0.252 D_B: 0.199 G_B: 0.297 cycle_B: 0.465 idt_B: 0.162 \n",
            "(epoch: 193, iters: 124, time: 3.755, data: 0.003) D_A: 0.123 G_A: 0.443 cycle_A: 0.464 idt_A: 0.229 D_B: 0.165 G_B: 0.543 cycle_B: 0.383 idt_B: 0.272 \n",
            "(epoch: 193, iters: 224, time: 1.388, data: 0.002) D_A: 0.083 G_A: 0.407 cycle_A: 0.351 idt_A: 0.251 D_B: 0.192 G_B: 0.684 cycle_B: 0.536 idt_B: 0.191 \n",
            "(epoch: 193, iters: 324, time: 1.394, data: 0.002) D_A: 0.126 G_A: 0.844 cycle_A: 0.462 idt_A: 0.205 D_B: 0.163 G_B: 0.372 cycle_B: 0.326 idt_B: 0.231 \n",
            "(epoch: 193, iters: 424, time: 1.399, data: 0.002) D_A: 0.119 G_A: 0.283 cycle_A: 1.527 idt_A: 0.189 D_B: 0.148 G_B: 0.369 cycle_B: 0.567 idt_B: 0.381 \n",
            "(epoch: 193, iters: 524, time: 3.674, data: 0.002) D_A: 0.142 G_A: 0.658 cycle_A: 0.771 idt_A: 0.199 D_B: 0.124 G_B: 0.627 cycle_B: 0.310 idt_B: 0.359 \n",
            "(epoch: 193, iters: 624, time: 1.390, data: 0.002) D_A: 0.125 G_A: 0.343 cycle_A: 0.593 idt_A: 0.206 D_B: 0.267 G_B: 0.469 cycle_B: 0.431 idt_B: 0.301 \n",
            "End of epoch 193 / 200 \t Time Taken: 828 sec\n",
            "learning rate = 0.0000139\n",
            "(epoch: 194, iters: 96, time: 1.393, data: 0.002) D_A: 0.204 G_A: 0.656 cycle_A: 0.708 idt_A: 0.201 D_B: 0.117 G_B: 0.367 cycle_B: 0.447 idt_B: 0.195 \n",
            "(epoch: 194, iters: 196, time: 1.394, data: 0.002) D_A: 0.213 G_A: 0.378 cycle_A: 0.341 idt_A: 0.203 D_B: 0.240 G_B: 0.473 cycle_B: 0.390 idt_B: 0.188 \n",
            "(epoch: 194, iters: 296, time: 3.772, data: 0.002) D_A: 0.228 G_A: 0.482 cycle_A: 0.506 idt_A: 0.255 D_B: 0.181 G_B: 0.465 cycle_B: 0.523 idt_B: 0.213 \n",
            "(epoch: 194, iters: 396, time: 1.401, data: 0.002) D_A: 0.159 G_A: 0.580 cycle_A: 0.469 idt_A: 0.201 D_B: 0.125 G_B: 0.526 cycle_B: 0.421 idt_B: 0.207 \n",
            "(epoch: 194, iters: 496, time: 1.391, data: 0.002) D_A: 0.089 G_A: 0.838 cycle_A: 0.346 idt_A: 0.189 D_B: 0.064 G_B: 0.386 cycle_B: 0.311 idt_B: 0.290 \n",
            "(epoch: 194, iters: 596, time: 1.389, data: 0.002) D_A: 0.172 G_A: 0.575 cycle_A: 0.571 idt_A: 0.216 D_B: 0.119 G_B: 0.635 cycle_B: 0.352 idt_B: 0.224 \n",
            "End of epoch 194 / 200 \t Time Taken: 826 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 195, iters: 68, time: 3.658, data: 0.002) D_A: 0.181 G_A: 0.331 cycle_A: 0.428 idt_A: 0.223 D_B: 0.132 G_B: 0.670 cycle_B: 0.477 idt_B: 0.171 \n",
            "(epoch: 195, iters: 168, time: 1.393, data: 0.002) D_A: 0.146 G_A: 0.699 cycle_A: 0.498 idt_A: 0.158 D_B: 0.182 G_B: 0.263 cycle_B: 0.370 idt_B: 0.217 \n",
            "(epoch: 195, iters: 268, time: 1.401, data: 0.002) D_A: 0.142 G_A: 0.449 cycle_A: 0.644 idt_A: 0.183 D_B: 0.136 G_B: 0.627 cycle_B: 0.437 idt_B: 0.226 \n",
            "(epoch: 195, iters: 368, time: 1.389, data: 0.002) D_A: 0.127 G_A: 0.445 cycle_A: 0.467 idt_A: 0.192 D_B: 0.141 G_B: 0.576 cycle_B: 0.344 idt_B: 0.215 \n",
            "(epoch: 195, iters: 468, time: 3.767, data: 0.002) D_A: 0.162 G_A: 0.442 cycle_A: 0.504 idt_A: 0.197 D_B: 0.175 G_B: 0.503 cycle_B: 0.394 idt_B: 0.206 \n",
            "(epoch: 195, iters: 568, time: 1.392, data: 0.002) D_A: 0.131 G_A: 0.535 cycle_A: 0.459 idt_A: 0.227 D_B: 0.055 G_B: 0.645 cycle_B: 0.475 idt_B: 0.266 \n",
            "saving the model at the end of epoch 195, iters 12560\n",
            "End of epoch 195 / 200 \t Time Taken: 830 sec\n",
            "learning rate = 0.0000099\n",
            "(epoch: 196, iters: 40, time: 1.402, data: 0.002) D_A: 0.109 G_A: 0.527 cycle_A: 0.469 idt_A: 0.197 D_B: 0.178 G_B: 0.515 cycle_B: 0.502 idt_B: 0.240 \n",
            "(epoch: 196, iters: 140, time: 1.401, data: 0.002) D_A: 0.186 G_A: 0.306 cycle_A: 0.364 idt_A: 0.243 D_B: 0.178 G_B: 0.421 cycle_B: 0.391 idt_B: 0.187 \n",
            "(epoch: 196, iters: 240, time: 3.815, data: 0.002) D_A: 0.325 G_A: 0.346 cycle_A: 0.417 idt_A: 0.267 D_B: 0.123 G_B: 0.232 cycle_B: 0.361 idt_B: 0.166 \n",
            "(epoch: 196, iters: 340, time: 1.392, data: 0.002) D_A: 0.142 G_A: 0.338 cycle_A: 0.633 idt_A: 0.280 D_B: 0.337 G_B: 0.703 cycle_B: 0.523 idt_B: 0.446 \n",
            "(epoch: 196, iters: 440, time: 1.394, data: 0.002) D_A: 0.181 G_A: 0.509 cycle_A: 0.488 idt_A: 0.296 D_B: 0.154 G_B: 0.384 cycle_B: 0.454 idt_B: 0.213 \n",
            "(epoch: 196, iters: 540, time: 1.397, data: 0.002) D_A: 0.114 G_A: 0.646 cycle_A: 0.566 idt_A: 0.305 D_B: 0.166 G_B: 0.487 cycle_B: 0.499 idt_B: 0.269 \n",
            "End of epoch 196 / 200 \t Time Taken: 827 sec\n",
            "learning rate = 0.0000079\n",
            "(epoch: 197, iters: 12, time: 3.657, data: 0.002) D_A: 0.251 G_A: 0.441 cycle_A: 0.601 idt_A: 0.193 D_B: 0.181 G_B: 0.319 cycle_B: 0.366 idt_B: 0.318 \n",
            "(epoch: 197, iters: 112, time: 1.396, data: 0.002) D_A: 0.102 G_A: 0.159 cycle_A: 0.394 idt_A: 0.149 D_B: 0.235 G_B: 0.526 cycle_B: 0.362 idt_B: 0.256 \n",
            "(epoch: 197, iters: 212, time: 1.396, data: 0.002) D_A: 0.252 G_A: 0.334 cycle_A: 0.590 idt_A: 0.206 D_B: 0.156 G_B: 0.501 cycle_B: 0.345 idt_B: 0.259 \n",
            "(epoch: 197, iters: 312, time: 1.395, data: 0.002) D_A: 0.112 G_A: 0.636 cycle_A: 0.719 idt_A: 0.203 D_B: 0.196 G_B: 0.406 cycle_B: 0.528 idt_B: 0.194 \n",
            "(epoch: 197, iters: 412, time: 3.730, data: 0.002) D_A: 0.178 G_A: 0.511 cycle_A: 0.473 idt_A: 0.236 D_B: 0.122 G_B: 0.468 cycle_B: 0.436 idt_B: 0.213 \n",
            "(epoch: 197, iters: 512, time: 1.394, data: 0.002) D_A: 0.327 G_A: 0.661 cycle_A: 0.517 idt_A: 0.238 D_B: 0.104 G_B: 0.540 cycle_B: 0.468 idt_B: 0.194 \n",
            "(epoch: 197, iters: 612, time: 1.399, data: 0.002) D_A: 0.214 G_A: 0.154 cycle_A: 0.504 idt_A: 0.165 D_B: 0.309 G_B: 0.513 cycle_B: 0.296 idt_B: 0.293 \n",
            "End of epoch 197 / 200 \t Time Taken: 829 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 198, iters: 84, time: 1.390, data: 0.002) D_A: 0.096 G_A: 0.674 cycle_A: 0.506 idt_A: 0.165 D_B: 0.098 G_B: 0.693 cycle_B: 0.320 idt_B: 0.232 \n",
            "(epoch: 198, iters: 184, time: 3.656, data: 0.002) D_A: 0.192 G_A: 0.366 cycle_A: 0.551 idt_A: 0.315 D_B: 0.241 G_B: 0.560 cycle_B: 0.520 idt_B: 0.249 \n",
            "(epoch: 198, iters: 284, time: 1.408, data: 0.002) D_A: 0.112 G_A: 0.519 cycle_A: 0.535 idt_A: 0.235 D_B: 0.193 G_B: 0.562 cycle_B: 0.510 idt_B: 0.241 \n",
            "(epoch: 198, iters: 384, time: 1.395, data: 0.002) D_A: 0.124 G_A: 0.405 cycle_A: 0.380 idt_A: 0.244 D_B: 0.256 G_B: 0.430 cycle_B: 0.379 idt_B: 0.233 \n",
            "(epoch: 198, iters: 484, time: 1.395, data: 0.002) D_A: 0.195 G_A: 0.517 cycle_A: 0.503 idt_A: 0.221 D_B: 0.195 G_B: 0.408 cycle_B: 0.429 idt_B: 0.219 \n",
            "(epoch: 198, iters: 584, time: 3.737, data: 0.002) D_A: 0.126 G_A: 0.578 cycle_A: 0.531 idt_A: 0.213 D_B: 0.103 G_B: 0.571 cycle_B: 0.488 idt_B: 0.214 \n",
            "End of epoch 198 / 200 \t Time Taken: 829 sec\n",
            "learning rate = 0.0000040\n",
            "(epoch: 199, iters: 56, time: 1.395, data: 0.002) D_A: 0.062 G_A: 0.409 cycle_A: 0.505 idt_A: 0.188 D_B: 0.130 G_B: 0.334 cycle_B: 0.489 idt_B: 0.240 \n",
            "(epoch: 199, iters: 156, time: 1.392, data: 0.002) D_A: 0.140 G_A: 0.353 cycle_A: 0.874 idt_A: 0.191 D_B: 0.102 G_B: 0.426 cycle_B: 0.362 idt_B: 0.330 \n",
            "(epoch: 199, iters: 256, time: 1.393, data: 0.002) D_A: 0.194 G_A: 0.359 cycle_A: 0.367 idt_A: 0.240 D_B: 0.172 G_B: 0.386 cycle_B: 0.394 idt_B: 0.175 \n",
            "(epoch: 199, iters: 356, time: 3.753, data: 0.002) D_A: 0.199 G_A: 0.475 cycle_A: 0.438 idt_A: 0.269 D_B: 0.222 G_B: 0.331 cycle_B: 0.363 idt_B: 0.229 \n",
            "(epoch: 199, iters: 456, time: 1.400, data: 0.002) D_A: 0.104 G_A: 0.420 cycle_A: 0.415 idt_A: 0.167 D_B: 0.191 G_B: 0.527 cycle_B: 0.343 idt_B: 0.203 \n",
            "(epoch: 199, iters: 556, time: 1.387, data: 0.002) D_A: 0.139 G_A: 0.678 cycle_A: 0.607 idt_A: 0.240 D_B: 0.136 G_B: 0.370 cycle_B: 0.429 idt_B: 0.252 \n",
            "saving the latest model (epoch 199, total_steps 15000)\n",
            "End of epoch 199 / 200 \t Time Taken: 827 sec\n",
            "learning rate = 0.0000020\n",
            "(epoch: 200, iters: 28, time: 1.394, data: 0.002) D_A: 0.129 G_A: 0.475 cycle_A: 0.633 idt_A: 0.229 D_B: 0.084 G_B: 0.511 cycle_B: 0.403 idt_B: 0.229 \n",
            "(epoch: 200, iters: 128, time: 3.688, data: 0.002) D_A: 0.138 G_A: 0.461 cycle_A: 0.532 idt_A: 0.215 D_B: 0.132 G_B: 0.399 cycle_B: 0.437 idt_B: 0.191 \n",
            "(epoch: 200, iters: 228, time: 1.395, data: 0.003) D_A: 0.216 G_A: 0.497 cycle_A: 0.340 idt_A: 0.221 D_B: 0.160 G_B: 0.214 cycle_B: 0.494 idt_B: 0.135 \n",
            "(epoch: 200, iters: 328, time: 1.399, data: 0.002) D_A: 0.154 G_A: 0.329 cycle_A: 0.435 idt_A: 0.179 D_B: 0.111 G_B: 0.622 cycle_B: 0.400 idt_B: 0.228 \n",
            "(epoch: 200, iters: 428, time: 1.393, data: 0.002) D_A: 0.113 G_A: 0.442 cycle_A: 0.671 idt_A: 0.242 D_B: 0.084 G_B: 0.610 cycle_B: 0.686 idt_B: 0.284 \n",
            "(epoch: 200, iters: 528, time: 3.755, data: 0.002) D_A: 0.089 G_A: 0.507 cycle_A: 0.600 idt_A: 0.181 D_B: 0.151 G_B: 0.732 cycle_B: 0.314 idt_B: 0.224 \n",
            "(epoch: 200, iters: 628, time: 1.394, data: 0.002) D_A: 0.113 G_A: 0.381 cycle_A: 0.421 idt_A: 0.227 D_B: 0.105 G_B: 0.467 cycle_B: 0.322 idt_B: 0.209 \n",
            "saving the model at the end of epoch 200, iters 15700\n",
            "End of epoch 200 / 200 \t Time Taken: 830 sec\n",
            "learning rate = 0.0000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B0SIt_y71Ne"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}